{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.cmap'] = 'Greys'\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (mnist.train.images.shape)\n",
    "print (mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (mnist.test.images.shape)\n",
    "print (mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1a45a69c50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a44ef15f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_image = mnist.train.images[1]\n",
    "example_image_reshaped = example_image.reshape((28, 28)) # Can't render a line of 784 numbers\n",
    "example_label = mnist.train.labels[1]\n",
    "\n",
    "print (example_label)\n",
    "plt.imshow(example_image_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some helper functions to ease the definition of the model\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape))\n",
    "\n",
    "def conv(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def pool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input -> CONV (-> ReLU -> Pool) -> FC -> ReLU -> FC -> Softmax -> Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A score function (model) involving some layers\n",
    "\n",
    "# Reshape the input to look like a volume (Input)\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# A convolutional layer (CONV -> RELU -> POOL)\n",
    "W_conv = weight_variable([5, 5, 1, 32])\n",
    "b_conv = bias_variable([32])\n",
    "h_conv = tf.nn.relu(conv(x_image, W_conv) + b_conv)\n",
    "h_pool = pool(h_conv)\n",
    "\n",
    "# A densely connected layer (FC)\n",
    "W_fc1 = weight_variable([14*14*32, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool_flat = tf.reshape(h_pool, [-1, 14*14*32])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Another densely connected layer (for \"readout\") (FC)\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y = tf.matmul(h_fc1, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.92\n",
      "step 1000, training accuracy 1\n",
      "step 2000, training accuracy 1\n",
      "step 3000, training accuracy 1\n",
      "step 4000, training accuracy 1\n",
      "step 5000, training accuracy 1\n",
      "step 6000, training accuracy 1\n",
      "step 7000, training accuracy 1\n",
      "step 8000, training accuracy 1\n",
      "step 9000, training accuracy 0.98\n",
      "step 10000, training accuracy 1\n",
      "step 11000, training accuracy 1\n",
      "step 12000, training accuracy 1\n",
      "step 13000, training accuracy 1\n",
      "step 14000, training accuracy 1\n",
      "step 15000, training accuracy 1\n",
      "step 16000, training accuracy 1\n",
      "step 17000, training accuracy 1\n",
      "step 18000, training accuracy 1\n",
      "step 19000, training accuracy 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%1000 == 0:\n",
    "        train_accuracy = accuracy.eval(session=sess, feed_dict={\n",
    "            x:batch[0], y_: batch[1]})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(session=sess, feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9907\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
